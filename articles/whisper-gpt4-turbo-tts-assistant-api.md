---
title: "OpenAIã®Whisper, TTS, Assistants APIã§é•·æœŸè¨˜æ†¶ã‚’æŒã£ãŸéŸ³å£°ä¼šè©±å‹ãƒœãƒƒãƒˆã‚’ä½œã‚‹"
emoji: "ğŸ¤–"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics:
  - "ChatGPT"
  - "OpenAI"
published: true
---

ã“ã‚“ã«ã¡ã‚ã€‚ [ZUMA](https://twitter.com/zuma_lab) ã§ã™ã€‚

11/6ã«OpenAI DevDayãŒé–‹å‚¬ã•ã‚Œæ§˜ã€…ãªç™ºè¡¨ãŒã‚ã‚Šã¾ã—ãŸã­ã€‚

https://devday.openai.com/

ç™ºè¡¨ã•ã‚ŒãŸæ–°ã—ã„APIã‚’ä½¿ã£ã¦é•·æœŸè¨˜æ†¶ã‚’æŒã£ãŸéŸ³å£°ä¼šè©±å‹ãƒœãƒƒãƒˆã‚’ä½œã£ã¦ã¿ã¾ã—ãŸã€‚

éŸ³å£°æ–‡å­—èµ·ã“ã—ã«Whisperã€æ¨è«–å®Ÿè¡Œã«GPT-4 Turboã€æ–‡å­—ã‹ã‚‰éŸ³å£°ã®ç”Ÿæˆã«TTSã€é•·æœŸè¨˜æ†¶ä¿æŒã«ã¯Assistants APIã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚

# æˆæœç‰©

ä»¥ä¸‹æˆæœç‰©ã¨ãªã‚Šã¾ã™ã€‚

https://twitter.com/zuma_lab/status/1722428441319100546

Assistants APIã®threadã§ä¼šè©±å±¥æ­´ã‚’æŒã£ã¦ã„ã‚‹ã®ã§ã€æ–‡è„ˆã‚’èª­ã‚“ã§å›ç­”ã‚’ã—ã¦ãã‚Œã¾ã™ã€‚

ã¾ãŸã€é–¢è¥¿å¼ã§ã—ã‚ƒã¹ã‚‹ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚­ãƒ£ãƒ©ã‚’è¨­å®šã—ã¦ã„ã¾ã™ã€‚

# äº‹å‰æº–å‚™

```py
%pip install openai
%pip install pydub
%pip install sounddevice scipy
```

å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’installã—ã¾ã™ã€‚

```py
import os

os.environ["OPENAI_API_KEY"] = "Your API Key"
```

è‡ªèº«ã®OpenAI API Keyã‚’è¨­å®šã—ã¾ã™ã€‚

# Assistantã®ä½œæˆ

```py
from openai import OpenAI

client = OpenAI()

assistant_name = "My AI Assistant"

model_name = "gpt-4-1106-preview"

instructions = """
ã‚ãªãŸã¯å„ªç§€ãªä¼šè©±å‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ã‚ãªãŸã¯ã¨ã¦ã‚‚ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªæ€§æ ¼ã§å¸¸ã«ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãŒé«˜ã„ã§ã™ã€‚

### æŒ‡ç¤º

- é–¢è¥¿å¼ã§è©±ã—ã¦ãã ã•ã„ã€‚
- 200æ–‡å­—ä»¥å†…ã§å›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚
"""

assistant = client.beta.assistants.create(
    name=assistant_name,
    model=model_name,
    instructions=instructions,
)
```

ä»Šå›æ–°ãŸã«è¿½åŠ ã•ã‚ŒãŸAssistants APIã‚’ä½¿ã£ã¦Assistantã‚’ä½œæˆã—ã¾ã™ã€‚

ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆè­˜åˆ¥å­ã® `name` ä½¿ç”¨ã™ã‚‹GPTã®ãƒ¢ãƒ‡ãƒ«åã® `model` ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã® `instructions` ã‚’è¨­å®šã—ã¾ã™ã€‚

11/14ç¾åœ¨ã€ã¾ã GPT-4 Turboã¯å®‰å®šç‰ˆã§ã¯ãªã„ã®ã§ã€ä»Šå›ã¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆã® `gpt-4-1106-preview` ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚

`instructions` ã§é–¢è¥¿å¼ã§è©±ã™ã‚ˆã†ã«æŒ‡ç¤ºã—ã¦ã„ã¾ã™ã€‚

ã¾ãŸã€éŸ³å£°ä¼šè©±å‹ã®ãƒœãƒƒãƒˆãªã®ã§ã€ãªã‚‹ã¹ãæ¨è«–é€Ÿåº¦ã‚’ä¸Šã’ã‚‹ç‚º200æ–‡å­—ä»¥å†…ã§å›ç­”ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã—ã¦ã„ã¾ã™ã€‚

Assistants APIã«ã¯Chat Completion APIã® `max_tokens` ã®ã‚ˆã†ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãŒç„¡ã„ã®ã§ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æ–‡å­—æ•°åˆ¶é™ã‚’ã—ã¦ã„ã¾ã™ã€‚

æ–‡å­—æ•°åˆ¶é™ã‚’ã—ãªã„ã¨é•·ã„æ¨è«–çµæœãŒå‡ºåŠ›ã•ã‚ŒãŸå ´åˆã€GPT-4 Turboã€TTSã§æ™‚é–“ãŒã‹ã‹ã‚Šéãã¦ã—ã¾ã„ä¼šè©±ã™ã‚‹æ°—ãŒå¤±ã›ã¦ã—ã¾ã„ã¾ã™ãƒ»ãƒ»ãƒ»

ã¡ãªã¿ã«ä½œæˆã—ãŸassistantã¯OpenAIã®PlayGroundã§ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/562e4a147482-20231113.png)


ä»Šå›å¿…è¦æœ€ä½é™ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®ã¿è¨­å®šã—ã¦ã„ã¾ã™ã®ã§ã€ç´°ã‹ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã«ã¤ã„ã¦ã¯ä»¥ä¸‹ã‚’å‚ç…§ãã ã•ã„ã€‚

https://platform.openai.com/docs/api-reference/assistants/createAssistant


# AI Assistant ã‚¯ãƒ©ã‚¹ã®ä½œæˆ

æ¬¡ã«AI Assistantã‚¯ãƒ©ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

å½¹å‰²ã¨ã—ã¦ã€éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ã€Whisperã§éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹ã€GPT-4 Turboã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã€TTSã§æ–‡å­—ã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆã—ã¦å†ç”Ÿã™ã‚‹ã€ã®4ã¤ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚

å…¨æ–‡ã¯ã“ã¡ã‚‰ã§ã™ã€‚

:::details AIAssistant Class

```py
import io
import time
import sounddevice as sd
from scipy.io.wavfile import write
from openai import OpenAI
from pydub import AudioSegment
from pydub.playback import play


class AIAssistant:
    """
    OpenAIã®APIã‚’åˆ©ç”¨ã—ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§å‡¦ç†ã—ã€éŸ³å£°ã«æˆ»ã™ã‚¯ãƒ©ã‚¹ã€‚
    """

    # éŒ²éŸ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    fs = 44100  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
    duration = 5  # éŒ²éŸ³ã™ã‚‹ç§’æ•°
    channels = 1  # ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³
    # éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«
    stt_model = "whisper-1"
    # éŸ³å£°ç”Ÿæˆãƒ¢ãƒ‡ãƒ«
    tts_model = "tts-1"  # é«˜å“è³ªãƒ¢ãƒ‡ãƒ« tts-1-hd
    # å£°è³ª
    voice_code = "nova"  # ç”·æ€§ alloy, echo, fable, onyx å¥³æ€§ nova, shimmer

    def __init__(self, assistant_id: str, output_audio_file: str = "./output.wav"):
        """
        åˆæœŸåŒ–å‡¦ç†ã€‚

        Args:
            assistant_id (str): AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®IDã€‚
            output_audio_file (str, optional): éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜å…ˆã€‚
        """
        self.assistant_id = assistant_id
        self.client = OpenAI()
        thread = self.client.beta.threads.create()
        self.thread_id = thread.id
        self.output_audio_file = output_audio_file

    def record_audio(self) -> any:
        """
        ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’éŒ²éŸ³ã™ã‚‹ã€‚

        Returns:
            any: éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã€‚
        """
        print("Start recording...")
        recorded_data = sd.rec(
            int(self.duration * self.fs), samplerate=self.fs, channels=self.channels
        )
        sd.wait()  # éŒ²éŸ³ãŒçµ‚ã‚ã‚‹ã¾ã§å¾…æ©Ÿ
        print("...Finished recording")
        return recorded_data

    def transcribe_audio(self, audio_data: any) -> str:
        """
        éŒ²éŸ³ã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ã€‚

        Args:
            audio_data (any): éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã€‚

        Returns:
            str: å¤‰æ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€‚
        """
        write(self.output_audio_file, self.fs, audio_data)
        with open(self.output_audio_file, "rb") as audio_file:
            transcript = self.client.audio.transcriptions.create(
                model=self.stt_model, file=audio_file
            )
        return transcript.text

    def run_thread_actions(self, text: str) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«é€ä¿¡ã—ã€å¿œç­”ã‚’å–å¾—ã™ã‚‹ã€‚

        Args:
            text (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã€‚

        Returns:
            str: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‹ã‚‰ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã€‚
        """
        self.client.beta.threads.messages.create(
            thread_id=self.thread_id,
            role="user",
            content=text,
        )

        run = self.client.beta.threads.runs.create(
            thread_id=self.thread_id,
            assistant_id=self.assistant_id,
        )

        while True:
            result = self.client.beta.threads.runs.retrieve(
                thread_id=self.thread_id, run_id=run.id
            )
            if result.status == "completed":
                break
            time.sleep(0.5)

        messages = self.client.beta.threads.messages.list(
            thread_id=self.thread_id, order="asc"
        )

        if len(messages.data) < 2:
            return ""

        return messages.data[-1].content[0].text.value

    def text_to_speech(self, text: str) -> None:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›ã—ã€å†ç”Ÿã™ã‚‹ã€‚

        Args:
            text (str): å†ç”Ÿã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã€‚
        """
        response = self.client.audio.speech.create(
            model=self.tts_model,
            voice=self.voice_code,
            input=text,
        )

        byte_stream = io.BytesIO(response.content)

        audio = AudioSegment.from_file(byte_stream, format="mp3")

        play(audio)
```

:::

# éŸ³å£°ä¼šè©±ã‚’å®Ÿè¡Œã™ã‚‹

```py
ai_assistant = AIAssistant(assistant_id=assistant.id)

while True:
    recorded_data = ai_assistant.record_audio()
    transcript_text = ai_assistant.transcribe_audio(recorded_data)
    print(f"user: {transcript_text}")

    if not transcript_text:
        break

    assistant_content = ai_assistant.run_thread_actions(transcript_text)
    print(f"assistant: {assistant_content}")
    ai_assistant.text_to_speech(assistant_content)
```

AI Assistant ã‚¯ãƒ©ã‚¹ã‚’ä½¿ã£ã¦éŸ³å£°ä¼šè©±ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

`while` ãƒ«ãƒ¼ãƒ—ã§éŸ³å£°ã‚’éŒ²éŸ³ã—ã€Whisperã§æ–‡å­—èµ·ã“ã—ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€å¿œç­”ã‚’å–å¾—ã—ã¦éŸ³å£°ã«å¤‰æ›ã—ã¦å†ç”Ÿã—ã¦ã„ã¾ã™ã€‚

Assistants APIã®threadã§ä¼šè©±å±¥æ­´ã‚’ä¿æŒã—ã¦ã„ã‚‹ã®ã§ã€æ–‡è„ˆã‚’èª­ã‚“ã§å›ç­”ã‚’ã—ã¦ãã‚Œã¾ã™ã€‚

Chat Completion APIã ã¨ã€ä¼šè©±å±¥æ­´ã®ä¿æŒã«DBã‚„å¤–éƒ¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ä½¿ã†ãªã©å·¥å¤«ãŒå¿…è¦ã§ã—ãŸãŒã€Assistants APIã ã¨ã¨ã¦ã‚‚ç°¡å˜ã«ä¼šè©±å±¥æ­´ã‚’ä¿æŒã§ãã¾ã™ã€‚

ãã‚Œã§ã¯ã©ã®ã‚ˆã†ã«å„APIã‚’å‘¼ã³å‡ºã—ã¦ã„ã‚‹ã‹ã€AI Assistantã‚¯ãƒ©ã‚¹ã®å„é–¢æ•°ã‚’è¦‹ã¦ã„ãã¾ã™ã€‚

# AI Assistant ã‚¯ãƒ©ã‚¹ã®é–¢æ•°è§£èª¬

## åˆæœŸåŒ–å‡¦ç†

```py
class AIAssistant:
    """
    OpenAIã®APIã‚’åˆ©ç”¨ã—ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§å‡¦ç†ã—ã€éŸ³å£°ã«æˆ»ã™ã‚¯ãƒ©ã‚¹ã€‚
    """

    # éŒ²éŸ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    fs = 44100  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
    duration = 5  # éŒ²éŸ³ã™ã‚‹ç§’æ•°
    channels = 1  # ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³
    # éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«
    stt_model = "whisper-1"
    # éŸ³å£°ç”Ÿæˆãƒ¢ãƒ‡ãƒ«
    tts_model = "tts-1"  # é«˜å“è³ªãƒ¢ãƒ‡ãƒ« tts-1-hd
    # å£°è³ª
    voice_code = "nova"  # alloy, echo, fable, onyx, nova, shimmer

    def __init__(self, assistant_id: str, output_audio_file: str = "./output.wav"):
        """
        åˆæœŸåŒ–å‡¦ç†ã€‚

        Args:
            assistant_id (str): AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®IDã€‚
            output_audio_file (str, optional): éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜å…ˆã€‚
        """
        self.assistant_id = assistant_id
        self.client = OpenAI()
        thread = self.client.beta.threads.create()
        self.thread_id = thread.id
        self.output_audio_file = output_audio_file
```

### ã‚¯ãƒ©ã‚¹å¤‰æ•°ã§ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã™ã‚‹

AIAssistantã®ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ã¯éŒ²éŸ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã€éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã€éŸ³å£°ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€å£°è³ªã‚’è¨­å®šã—ã¦ã„ã¾ã™ã€‚

éŸ³å£°æ–‡å­—èµ·ã“ã—ã® Whisperãƒ¢ãƒ‡ãƒ«ã¯ç¾åœ¨ã®æ‰€ `whisper-1` ã®ã¿ã§ã™ã€‚

OpenAI DevDayã§ large-v3 whisperãƒ¢ãƒ‡ãƒ«ãŒç™ºè¡¨ã•ã‚Œã¾ã—ãŸãŒã€ã¾ã APIã¯æœªå…¬é–‹ãªã®ã§ã€ä»Šå›ã¯ `whisper-1` ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚

éŸ³å£°ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯æ¨™æº–å“è³ªã® `tts-1` ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€é«˜å“è³ªã® `tts-1-hd` ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ã¾ã è©¦ã—ãã‚Œã¦ã„ã¾ã›ã‚“ãŒã€æ—¥æœ¬èªã ã¨ä½“æ„Ÿã§ã¯ `tts-1` ã¨ `tts-1-hd` ã®å“è³ªå·®ç•°ã€ç”Ÿæˆé€Ÿåº¦ã«å·®ãŒã‚ã¾ã‚Šãªã‹ã£ãŸã§ã™ã€‚

https://platform.openai.com/docs/guides/text-to-speech

ã“ã¡ã‚‰ã§ã‚‚ä»¥ä¸‹ã®è¨˜è¼‰ãŒã‚ã‚Šã¾ã™ã­ã€‚

> å ´åˆã«ã‚ˆã£ã¦ã¯ã€ãƒªã‚¹ãƒ‹ãƒ³ã‚°ãƒ‡ãƒã‚¤ã‚¹ã‚„å€‹äººã«ã‚ˆã£ã¦ã¯ã€éŸ³å£°ã«é¡•è‘—ãªé•ã„ãŒæ„Ÿã˜ã‚‰ã‚Œãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

å£°è³ªã¯ `alloy, echo, fable, onyx, nova, shimmer` ã®6ç¨®é¡ã‹ã‚‰é¸æŠã§ãã¾ã™ã€‚

å€‹äººçš„ã«ä¸€ç•ªé–¢è¥¿å¼ãŒä¸Šæ‰‹ã‹ã£ãŸ(?) `nova` ã‚’è¨­å®šã—ã¦ã„ã¾ã™ã€‚

### ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã§assistant_id, thread_idã‚’è¨­å®šã™ã‚‹

ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã¯ã€å„APIã§ä½¿ç”¨ã™ã‚‹assistant_id, thread_idã‚’è¨­å®šã—ã¦ã„ã¾ã™ã€‚

ã“ã®2ã¤ã®IDã¯ä»¥ä¸‹ã§ä½œæˆã—ãŸthreadã‚’å®Ÿè¡Œã™ã‚‹éš›ã«åˆ©ç”¨ã—ã¾ã™ã€‚

```py
thread = self.client.beta.threads.create()
```

ã“ã“ã§ç”Ÿæˆã—ã¦ã„ã‚‹threadã¯ä¼šè©±ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã€ä»Šå›ã¯ä¼šè©±å±¥æ­´ã‚’ä¿æŒã™ã‚‹ç›®çš„ã§ä½¿ç”¨ã—ã¾ã™ã€‚

ã“ã“ã§ã¯ç´ ã®threadã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ãŒã€`create` æ™‚ã« `messages` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§æœ€åˆã®ä¼šè©±ã‚’è¨­å®šã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

`messages` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã«ã¤ã„ã¦ã¯ã“ã¡ã‚‰ã‚’å‚ç…§ãã ã•ã„ã€‚

https://platform.openai.com/docs/api-reference/threads/createThread


## éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹

```py
    def record_audio(self) -> any:
        """
        ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’éŒ²éŸ³ã™ã‚‹ã€‚

        Returns:
            any: éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã€‚
        """
        print("Start recording...")
        recorded_data = sd.rec(
            int(self.duration * self.fs), samplerate=self.fs, channels=self.channels
        )
        sd.wait()
        print("...Finished recording")
        return recorded_data
```

`sounddevice` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ã„ã¾ã™ã€‚

`sd.rec` ã§éŒ²éŸ³ã‚’é–‹å§‹ã—ã€ `sd.wait` ã§éŒ²éŸ³ãŒçµ‚ã‚ã‚‹ã¾ã§å¾…æ©Ÿã—ã¦ã„ã¾ã™ã€‚

éŒ²éŸ³æ™‚é–“ã¯ã‚¯ãƒ©ã‚¹å¤‰æ•°ã® `self.duration` ã§5ç§’ã«è¨­å®šã—ã¦ã„ã¾ã™ã€‚

ç„¡éŸ³æ™‚é–“ãŒç¶šãã¨è‡ªå‹•ã§éŒ²éŸ³åœæ­¢ã§ããŸæ–¹ãŒUXãŒè‰¯ã„ã®ã§ã™ãŒã€ä»Šå›ã¯ãƒ©ã‚¤ãƒˆã«å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚

## Whisperã§éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹

```py
    def transcribe_audio(self, audio_data: any) -> str:
        """
        éŒ²éŸ³ã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ã€‚

        Args:
            audio_data (any): éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã€‚

        Returns:
            str: å¤‰æ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€‚
        """
        write(self.output_audio_file, self.fs, audio_data)
        with open(self.output_audio_file, "rb") as audio_file:
            transcript = self.client.audio.transcriptions.create(
                model=self.stt_model, file=audio_file
            )
        return transcript.text
```

`pydub` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ã‚’ `output_audio_file` ã«ä¿å­˜ã—ã€ `openai` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦Whisperã§æ–‡å­—èµ·ã“ã—ã—ã¦ã„ã¾ã™ã€‚

ã“ã“ã§ã¯å¿…è¦æœ€ä½é™ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã—ã‹è¨­å®šã—ã¦ã„ãªã„ç‚ºã€ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã«ã¤ã„ã¦ã¯ä»¥ä¸‹ã‚’å‚ç…§ãã ã•ã„ã€‚

https://platform.openai.com/docs/api-reference/audio/createTranscription

ä½™è«‡ã§ã™ãŒã€å®Ÿé¨“ã—ã¦ã„ã¦ç™ºè¦‹ã—ãŸã®ãŒã€Whisperã«ç„¡éŸ³ã®wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€ã£ã¦ã‚‚ç©ºæ–‡å­—ãŒè¿”å´ã•ã‚Œã‚‹ã¨æ€ã„ãã‚„ã€ `.` ã‚„ `. .` ãªã©ã®ãƒ”ãƒªã‚ªãƒ‰ã®ã¿ã®æ–‡å­—åˆ—ãŒè¿”ã£ã¦ãã¾ã™ã€‚

ã¾ãŸã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®ã‚¿ãƒƒãƒéŸ³ã‚„æ‹æ‰‹ã®éŸ³ãªã©äººã®éŸ³å£°ä»¥å¤–ã®wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€ä¿¡ã™ã‚‹ã¨ã€`ãŠã‚„ã™ã¿ãªã•ã„`, `ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ`, `ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ãŠé¡˜ã„ã—ã¾ã™` ã‚„ `Thank you for watching.` ãªã©YouTuberã£ã½ã„ä¼šè©±ã®çµ‚ã‚ã‚Šã®æŒ¨æ‹¶ã‚’è¿”ã—ã¾ã™ã€‚

ä½•ãŒãªã‚“ã§ã‚‚æ–‡å­—èµ·ã“ã—ã‚’ã—ãŸã„ã®ã§ã—ã‚‡ã†ã‹ã€‚

å‹æ‰‹ãªæ–‡å­—ã‚’ç”Ÿæˆã•ã‚Œã¦ã¯å›°ã‚‹ã‚±ãƒ¼ã‚¹ã‚‚ã‚ã‚‹ã¨æ€ã†ã®ã§ `prompt` ã§ç„¡éŸ³æ™‚ã®èª¿æ•´ã‚„ `temperature` ã§ç”Ÿæˆçµæœã‚’å›ºå®šåŒ–ã§ããŸã‚Šã™ã‚‹ã®ã‹ã€ã¾ãŸåˆ¥ã®æ©Ÿä¼šã«è©¦ã—ã¦ã¿ã¾ã™ã€‚

## GPT-4 Turboã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹


ä¸€ç•ªé‡è¦ãªéƒ¨åˆ†ã€Assistants APIã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°ã§ã™ã€‚

https://platform.openai.com/docs/assistants/how-it-works

ã“ã¡ã‚‰ã¯OpenAIã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æŠœç²‹ã—ãŸAssistants APIã®å›³ã§ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/7d2aca6421bc-20231114.png)

ä»¥ä¸‹ã¯ç›¸é–¢é–¢ä¿‚ã‚’ç¿»è¨³ã—ãŸã‚‚ã®ã§ã™ã€‚

```
Assistantã¯ OpenAI ã®Modelã‚’ä½¿ç”¨ã—ã€Toolsã‚’å‘¼ã³å‡ºã™ AI ã§ã™ã€‚

ä¸€ã¤ã®Threadã«ã¯Messageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚¹ãƒˆã‚’å†…åŒ…ã—ã¦ã„ã¾ã™ã€‚

Messageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯Userã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ, Assistantã®æ¨è«–çµæœã‚’ä¿æŒã—ã¦ã„ã¾ã™ã€‚

Messageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ãƒ†ã‚­ã‚¹ãƒˆã®ä»–ã€ç”»åƒã€ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

Runã¯Threadä¸Šã®Assistantã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚

Assistantã¯ã€Threadã®Messageã‚’ä½¿ç”¨ã—ã¦ã€Modelã¨Toolsã‚’å‘¼ã³å‡ºã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

Run Stepã¯AssistantãŒå®Ÿè¡Œã—ãŸã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°ãªãƒªã‚¹ãƒˆã§ã™ã€‚

Assistantã¯ã€ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œä¸­ã«Toolsã‚’å‘¼ã³å‡ºã—ãŸã‚Šã€æ–°ãŸã«Messageã‚’ä½œæˆã—ãŸã‚Šã§ãã¾ã™ã€‚

å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ã‚’èª¿ã¹ã‚‹ã¨ã€AssistantãŒæœ€çµ‚çµæœã«ã©ã®ã‚ˆã†ã«åˆ°é”ã™ã‚‹ã‹ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
```

è‡ªåˆ†ã¯æœ€åˆã¡ã‚‡ã£ã¨è‰¯ãåˆ†ã‹ã‚‰ãªã‹ã£ãŸã§ã™ãŒã€ä»Šã¯å‹æ‰‹ã«ã“ã‚“ãªç†è§£ã‚’ã—ã¦ã„ã¾ã™ã€‚

è¦ã™ã‚‹ã« Assistant ã¯ AI, Thread ã¯ä¼šè©±ã®æ–‡è„ˆã€Message ã¯ä¼šè©±ã®å†…å®¹ã‚’ä¿æŒã—ã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚

Assistant ã¨ Thread ã®é–“ã«ã¯ç›´æ¥çš„ãªé–¢ä¿‚æ€§ã¯ç„¡ãã€ä¸­é–“ãƒ†ãƒ¼ãƒ–ãƒ«çš„ã« Run ãŒã‚ã£ã¦ã€Run ã¯ Assistant ã¨ Thread ã‚’ç´ä»˜ã‘ã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚

Runã‚’å®Ÿè¡Œã™ã‚‹ã¨ç´ã¥ã„ã¦ã‚‹ Assistant ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

Assistantã¯ã€Threadã®Messageã®å†…å®¹ã‹ã‚‰ã€Modelã¨Toolsã‚’å‘¼ã³å‡ºã—ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦Retrievalã‚„Code Interpreter, Function CallingãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

Run Stepã¯ãã®ã‚¿ã‚¹ã‚¯ã®1ã¤1ã¤ã®å®Ÿè¡Œå±¥æ­´ã‚’ãƒªã‚¹ãƒˆã§ä¿æŒã—ã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚

Assistants APIã¯Assistantã€Threadã€Messageå˜ä½“ã§ã¯ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹äº‹ã¯ã§ããšã€Runã‚’å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

ãªã®ã§ã€Chat Completions APIã«ã¯ç„¡ã‹ã£ãŸæ–°ã—ã„æ¦‚å¿µã® Run ãŒç‰¹ã«é‡è¦ã«ãªã‚Šã¾ã™ã€‚

å‰ç½®ããŒé•·ããªã‚Šã¾ã—ãŸãŒã€ `run_thread_actions` é–¢æ•°ã®å‡¦ç†ã‚’è¦‹ã¦ã„ãã¾ã™ã€‚

```py
    def run_thread_actions(self, text: str) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«é€ä¿¡ã—ã€å¿œç­”ã‚’å–å¾—ã™ã‚‹ã€‚

        Args:
            text (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã€‚

        Returns:
            str: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‹ã‚‰ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã€‚
        """
        self.client.beta.threads.messages.create(
            thread_id=self.thread_id,
            role="user",
            content=text,
        )

        run = self.client.beta.threads.runs.create(
            thread_id=self.thread_id,
            assistant_id=self.assistant_id,
        )

        while True:
            result = self.client.beta.threads.runs.retrieve(
                thread_id=self.thread_id, run_id=run.id
            )
            if result.status == "completed":
                break
            time.sleep(0.5)

        messages = self.client.beta.threads.messages.list(
            thread_id=self.thread_id, order="asc"
        )

        if len(messages.data) < 2:
            return ""

        return messages.data[-1].content[0].text.value
```

ã¾ãšã€Threadã®Messageã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¨­å®šã—ã¾ã™ã€‚

```py
self.client.beta.threads.messages.create(
    thread_id=self.thread_id,
    role="user",
    content=text,
)
```

`thread_id`, `role` ã¨ `content` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¯å¿…é ˆã§ã™ã€‚

ä»Šå›ã¯ãƒãƒ£ãƒƒãƒˆã®ã¿ã®ç”¨é€”ãªã®ã§æœ€ä½é™ã®è¨­å®šã®ã¿ã—ã¾ã™ã€‚

Retrievalã‹Code Interpreterã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®IDã‚’æŒ‡å®šã™ã‚‹äº‹ãŒã§ãã¾ã™ã€‚

è©³ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¯ã“ã¡ã‚‰ã‚’å‚ç…§ãã ã•ã„ã€‚

https://platform.openai.com/docs/api-reference/messages/createMessage

æ¬¡ã«Assistantã¨Threadã‚’ç´ã¥ã‘ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹Runã‚’ä½œæˆã—ã¾ã™ã€‚

```py
run = self.client.beta.threads.runs.create(
    thread_id=self.thread_id,
    assistant_id=self.assistant_id,
)
```

Runã¯ `thread_id` ã¨ `assistant_id` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãŒå¿…é ˆã§ã™ã€‚

ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦ã€`model`, `instructions`, `tools` ã¨ `metadata` ãŒæŒ‡å®šã§ãã¾ã™ã€‚

`model`, `instructions`, `tools` ã¯Assistantã®è¨­å®šã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å‡ºæ¥ã‚‹ã‚‰ã—ã„ã§ã™ã€‚

`file_ids` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãŒç„¡ã„ã®ã§ã€ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®šã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã¯å‡ºæ¥ãªã„ã‚ˆã†ã§ã™ã€‚

è©³ã—ãã¯ã“ã¡ã‚‰ã‚’å‚ç…§ãã ã•ã„ã€‚

https://platform.openai.com/docs/api-reference/runs/createRun

æ¬¡ã«Runã® `retrieve` ã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```py
while True:
    result = self.client.beta.threads.runs.retrieve(
        thread_id=self.thread_id, run_id=run.id
    )
    if result.status == "completed":
        break
    time.sleep(0.5)
```

retrieveã¯ `thread_id` ã¨ `run_id` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãŒå¿…é ˆã§ã™ã€‚

https://platform.openai.com/docs/api-reference/runs/getRun

Runã¯ã‚¿ã‚¹ã‚¯ãŒã‚­ãƒ¥ãƒ¼ã§å®Ÿè¡Œã•ã‚Œã‚‹ç‚ºã€å®šæœŸçš„ã« `retrieve` å®Ÿè¡Œã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ã—ã¦ `completed` ã«ç§»è¡Œã—ãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚

ã‚­ãƒ¥ãƒ¼ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ `completed` ã«ãªã£ãŸã‚‰ `messages.list` ã§ä¼šè©±å±¥æ­´ã‚’å–å¾—ã—ã€æœ€å¾Œã®Messageã‚’è¿”ã—ã¾ã™ã€‚

```py
messages = self.client.beta.threads.messages.list(
    thread_id=self.thread_id, order="asc"
)

if len(messages.data) < 2:
    return ""

return messages.data[-1].content[0].text.value
```

ã“ã®æœ€å¾Œã®MessageãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã™ã‚‹æœ€çµ‚çš„ãªAssistantã®å›ç­”ã«ãªã‚Šã¾ã™ã€‚

ã“ã® messages.list ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§20ä»¶ã¾ã§Messageã‚’è¿”ã—ã¾ã™ãŒã€ã‚ˆã‚Šå¤šãã®æ–‡è„ˆã‚’å–å¾—ã—ãŸã„å ´åˆã€ `limit` ã§100ä»¶ã¾ã§å–å¾—å¯èƒ½ã§ã™ã€‚

è©³ã—ãã¯ã“ã¡ã‚‰ã‚’å‚ç…§ãã ã•ã„ã€‚

https://platform.openai.com/docs/api-reference/messages/listMessages

## TTSã§æ–‡å­—ã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆã—ã¦å†ç”Ÿã™ã‚‹

```py
    def text_to_speech(self, text: str) -> None:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›ã—ã€å†ç”Ÿã™ã‚‹ã€‚

        Args:
            text (str): å†ç”Ÿã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã€‚
        """
        response = self.client.audio.speech.create(
            model=self.tts_model,
            voice=self.voice_code,
            input=text,
        )

        byte_stream = io.BytesIO(response.content)

        audio = AudioSegment.from_file(byte_stream, format="mp3")

        play(audio)
```

æœ€å¾Œã« `openai` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦TTSã§éŸ³å£°ã‚’ç”Ÿæˆã—ã€ `pydub` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦å†ç”Ÿã—ã¦ã„ã¾ã™ã€‚

`speed` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§éŸ³å£°ã®å†ç”Ÿé€Ÿåº¦ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ `1.0` ã§ã™ã€‚

ç­†è€…ã®å ´åˆã€è‹±èªéŸ³å£°ã®å†ç”Ÿã¯ãƒã‚¤ãƒ†ã‚£ãƒ–ä¸¦ã¿ã®æ—©å£ã§èãå–ã‚Œãªã„ã®ã§ã€1ä»¥ä¸‹ã®å€¤ã‚’æŒ‡å®šã—ã¦ã‚†ã£ãã‚Šå†ç”Ÿã—ã¦ã„ã¾ã™ã€‚

ãã®ä»–è©³ã—ãã¯ä»¥ä¸‹ã‚’å‚ç…§ãã ã•ã„ã€‚

https://platform.openai.com/docs/api-reference/audio/createSpeech

# ä½™è«‡

OpenAIã®PlayGroundã§Assistants APIã‚’è‰²ã€…è©¦ã—ã¦ã¿ã¦ã‚ã¾ã‚Šã«ä¾¿åˆ©ã ã£ãŸã®ã§ã€ã‚‚ã†Chat Completions APIã¯è¦ã‚‰ãªã„ã˜ã‚ƒãªã„ï¼Ÿ

ã¨æ€ã£ãŸã®ã§ã™ãŒã€ Assistants APIã¯ `max_tokens` ã‚„ `temperature`ã€ `seed` ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãŒè¦‹å½“ãŸã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚

æ›´ã«Assistants APIã«ã¯ã¾ã streamæ©Ÿèƒ½ãªã©ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚

ã¾ãŸã€åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦ã€Assistants APIã¨Chat Completions APIã‚’ä½•åº¦ã‚‚å®Ÿè¡Œã—ã¦ã¿ã¾ã—ãŸãŒã€Completions APIã®æ–¹ãŒä½“æ„Ÿ1.5å€ç¨‹é€Ÿãæ„Ÿã˜ã¾ã—ãŸã€‚

ãªã®ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ãªä½¿ã„æ–¹ã‚’ã—ãªã„ã®ã§ã‚ã‚Œã°ä»Šã¾ã§é€šã‚Š Chat Completions API ã‚’ä½¿ã†ã¹ãã‹ãªã¨æ€ã„ã¾ã—ãŸã€‚
